{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras + horovod + ipyparallel MNIST example\n",
    "\n",
    "In this notebook we will use ipyparallel to deploy a Keras + Horovod distributed training example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# System imports\n",
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "from __future__ import absolute_import\n",
    "\n",
    "# External imports\n",
    "import ipyparallel as ipp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to ipyparallel cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)\n",
      "          14800065     debug batchScr sfarrell PD       0:00     16 (None)\n",
      "          14799600 interacti       sh sfarrell  R       9:31     16 nid00[138,178-183,193,212-219]\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "squeue -u sfarrell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Worker IDs: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]\n"
     ]
    }
   ],
   "source": [
    "# Cluster ID taken from job ID above\n",
    "job_id = 14799600\n",
    "cluster_id = 'cori_{}'.format(job_id)\n",
    "\n",
    "# Use default profile\n",
    "c = ipp.Client(timeout=60, cluster_id=cluster_id)\n",
    "print('Worker IDs:', c.ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize environment on the workers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px\n",
    "\n",
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "\n",
    "import socket\n",
    "import math\n",
    "\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "\n",
    "# Horovod for MPI synchronization routines\n",
    "import horovod.keras as hvd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[stdout:0] MPI rank 0, local rank 0, host nid00138\n",
      "[stdout:1] MPI rank 11, local rank 0, host nid00215\n",
      "[stdout:2] MPI rank 6, local rank 0, host nid00183\n",
      "[stdout:3] MPI rank 5, local rank 0, host nid00182\n",
      "[stdout:4] MPI rank 10, local rank 0, host nid00214\n",
      "[stdout:5] MPI rank 4, local rank 0, host nid00181\n",
      "[stdout:6] MPI rank 8, local rank 0, host nid00212\n",
      "[stdout:7] MPI rank 9, local rank 0, host nid00213\n",
      "[stdout:8] MPI rank 3, local rank 0, host nid00180\n",
      "[stdout:9] MPI rank 2, local rank 0, host nid00179\n",
      "[stdout:10] MPI rank 7, local rank 0, host nid00193\n",
      "[stdout:11] MPI rank 14, local rank 0, host nid00218\n",
      "[stdout:12] MPI rank 13, local rank 0, host nid00217\n",
      "[stdout:13] MPI rank 12, local rank 0, host nid00216\n",
      "[stdout:14] MPI rank 15, local rank 0, host nid00219\n",
      "[stdout:15] MPI rank 1, local rank 0, host nid00178\n"
     ]
    }
   ],
   "source": [
    "%%px\n",
    "\n",
    "# Initialize horovod\n",
    "hvd.init()\n",
    "print('MPI rank %i, local rank %i, host %s' %\n",
    "      (hvd.rank(), hvd.local_rank(), socket.gethostname()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px\n",
    "\n",
    "# Data config\n",
    "n_classes = 10\n",
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "# Training config\n",
    "batch_size = 128\n",
    "n_epochs = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data on each worker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[stdout:0] \n",
      "x_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n",
      "[stdout:1] \n",
      "x_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n",
      "[stdout:2] \n",
      "x_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n",
      "[stdout:3] \n",
      "x_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n",
      "[stdout:4] \n",
      "x_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n",
      "[stdout:5] \n",
      "x_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n",
      "[stdout:6] \n",
      "x_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n",
      "[stdout:7] \n",
      "x_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n",
      "[stdout:8] \n",
      "x_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n",
      "[stdout:9] \n",
      "x_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n",
      "[stdout:10] \n",
      "x_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n",
      "[stdout:11] \n",
      "x_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n",
      "[stdout:12] \n",
      "x_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n",
      "[stdout:13] \n",
      "x_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n",
      "[stdout:14] \n",
      "x_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n",
      "[stdout:15] \n",
      "x_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "%%px\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "# Scale pixels to [0, 1]\n",
    "x_train = x_train.astype('float32') / 255\n",
    "x_test = x_test.astype('float32') / 255\n",
    "\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# Convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, n_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, n_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[stdout:0] \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_3 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 24, 24, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 9216)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 128)               1179776   \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,199,882\n",
      "Trainable params: 1,199,882\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "%%px\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(n_classes, activation='softmax'))\n",
    "\n",
    "# Adjust learning rate based on number of workers.\n",
    "opt = keras.optimizers.Adadelta(1.0 * hvd.size())\n",
    "\n",
    "# Add Horovod Distributed Optimizer.\n",
    "opt = hvd.DistributedOptimizer(opt)\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "if hvd.rank() == 0:\n",
    "    model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distributed training\n",
    "\n",
    "Training with horovod + MPI allows for synchronous distributed batch updates.\n",
    "\n",
    "We need to register the model synchronization callback and restrict checkpoint writing to a single worker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[stdout:0] \n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/8\n",
      " - 15s - loss: 0.2224 - acc: 0.9340 - val_loss: 0.0348 - val_acc: 0.9886\n",
      "Epoch 2/8\n",
      " - 14s - loss: 0.0405 - acc: 0.9867 - val_loss: 0.0327 - val_acc: 0.9900\n",
      "Epoch 3/8\n",
      " - 14s - loss: 0.0272 - acc: 0.9911 - val_loss: 0.0287 - val_acc: 0.9928\n",
      "Epoch 4/8\n",
      " - 15s - loss: 0.0916 - acc: 0.9857 - val_loss: 0.0358 - val_acc: 0.9922\n",
      "Epoch 5/8\n",
      " - 14s - loss: 0.0206 - acc: 0.9931 - val_loss: 0.0381 - val_acc: 0.9919\n",
      "Epoch 6/8\n",
      " - 14s - loss: 0.0172 - acc: 0.9943 - val_loss: 0.0328 - val_acc: 0.9918\n",
      "Epoch 7/8\n",
      " - 14s - loss: 0.0151 - acc: 0.9950 - val_loss: 0.0321 - val_acc: 0.9927\n",
      "Epoch 8/8\n",
      " - 15s - loss: 0.0144 - acc: 0.9951 - val_loss: 0.0322 - val_acc: 0.9933\n",
      "[stdout:1] \n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/8\n",
      " - 15s - loss: 0.2211 - acc: 0.9339 - val_loss: 0.0348 - val_acc: 0.9886\n",
      "Epoch 2/8\n",
      " - 14s - loss: 0.0371 - acc: 0.9882 - val_loss: 0.0327 - val_acc: 0.9900\n",
      "Epoch 3/8\n",
      " - 14s - loss: 0.0290 - acc: 0.9910 - val_loss: 0.0287 - val_acc: 0.9928\n",
      "Epoch 4/8\n",
      " - 15s - loss: 0.0917 - acc: 0.9858 - val_loss: 0.0358 - val_acc: 0.9922\n",
      "Epoch 5/8\n",
      " - 14s - loss: 0.0186 - acc: 0.9940 - val_loss: 0.0381 - val_acc: 0.9919\n",
      "Epoch 6/8\n",
      " - 14s - loss: 0.0161 - acc: 0.9946 - val_loss: 0.0328 - val_acc: 0.9918\n",
      "Epoch 7/8\n",
      " - 14s - loss: 0.0130 - acc: 0.9956 - val_loss: 0.0321 - val_acc: 0.9927\n",
      "Epoch 8/8\n",
      " - 15s - loss: 0.0127 - acc: 0.9957 - val_loss: 0.0322 - val_acc: 0.9933\n",
      "[stdout:2] \n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/8\n",
      " - 15s - loss: 0.2222 - acc: 0.9352 - val_loss: 0.0348 - val_acc: 0.9886\n",
      "Epoch 2/8\n",
      " - 14s - loss: 0.0401 - acc: 0.9876 - val_loss: 0.0327 - val_acc: 0.9900\n",
      "Epoch 3/8\n",
      " - 14s - loss: 0.0274 - acc: 0.9912 - val_loss: 0.0287 - val_acc: 0.9928\n",
      "Epoch 4/8\n",
      " - 15s - loss: 0.0953 - acc: 0.9854 - val_loss: 0.0358 - val_acc: 0.9922\n",
      "Epoch 5/8\n",
      " - 14s - loss: 0.0225 - acc: 0.9931 - val_loss: 0.0381 - val_acc: 0.9919\n",
      "Epoch 6/8\n",
      " - 14s - loss: 0.0155 - acc: 0.9948 - val_loss: 0.0328 - val_acc: 0.9918\n",
      "Epoch 7/8\n",
      " - 14s - loss: 0.0148 - acc: 0.9950 - val_loss: 0.0321 - val_acc: 0.9927\n",
      "Epoch 8/8\n",
      " - 15s - loss: 0.0151 - acc: 0.9952 - val_loss: 0.0322 - val_acc: 0.9933\n",
      "[stdout:3] \n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/8\n",
      " - 15s - loss: 0.2202 - acc: 0.9349 - val_loss: 0.0348 - val_acc: 0.9886\n",
      "Epoch 2/8\n",
      " - 14s - loss: 0.0420 - acc: 0.9869 - val_loss: 0.0327 - val_acc: 0.9900\n",
      "Epoch 3/8\n",
      " - 14s - loss: 0.0288 - acc: 0.9914 - val_loss: 0.0287 - val_acc: 0.9928\n",
      "Epoch 4/8\n",
      " - 15s - loss: 0.0928 - acc: 0.9851 - val_loss: 0.0358 - val_acc: 0.9922\n",
      "Epoch 5/8\n",
      " - 14s - loss: 0.0217 - acc: 0.9933 - val_loss: 0.0381 - val_acc: 0.9919\n",
      "Epoch 6/8\n",
      " - 14s - loss: 0.0184 - acc: 0.9941 - val_loss: 0.0328 - val_acc: 0.9918\n",
      "Epoch 7/8\n",
      " - 14s - loss: 0.0167 - acc: 0.9945 - val_loss: 0.0321 - val_acc: 0.9927\n",
      "Epoch 8/8\n",
      " - 15s - loss: 0.0126 - acc: 0.9956 - val_loss: 0.0322 - val_acc: 0.9933\n",
      "[stdout:4] \n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/8\n",
      " - 15s - loss: 0.2218 - acc: 0.9338 - val_loss: 0.0348 - val_acc: 0.9886\n",
      "Epoch 2/8\n",
      " - 14s - loss: 0.0402 - acc: 0.9873 - val_loss: 0.0327 - val_acc: 0.9900\n",
      "Epoch 3/8\n",
      " - 14s - loss: 0.0292 - acc: 0.9906 - val_loss: 0.0287 - val_acc: 0.9928\n",
      "Epoch 4/8\n",
      " - 15s - loss: 0.0931 - acc: 0.9859 - val_loss: 0.0358 - val_acc: 0.9922\n",
      "Epoch 5/8\n",
      " - 14s - loss: 0.0197 - acc: 0.9929 - val_loss: 0.0381 - val_acc: 0.9919\n",
      "Epoch 6/8\n",
      " - 14s - loss: 0.0156 - acc: 0.9943 - val_loss: 0.0328 - val_acc: 0.9918\n",
      "Epoch 7/8\n",
      " - 14s - loss: 0.0140 - acc: 0.9954 - val_loss: 0.0321 - val_acc: 0.9927\n",
      "Epoch 8/8\n",
      " - 15s - loss: 0.0138 - acc: 0.9958 - val_loss: 0.0322 - val_acc: 0.9933\n",
      "[stdout:5] \n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/8\n",
      " - 15s - loss: 0.2161 - acc: 0.9357 - val_loss: 0.0348 - val_acc: 0.9886\n",
      "Epoch 2/8\n",
      " - 14s - loss: 0.0400 - acc: 0.9873 - val_loss: 0.0327 - val_acc: 0.9900\n",
      "Epoch 3/8\n",
      " - 14s - loss: 0.0278 - acc: 0.9908 - val_loss: 0.0287 - val_acc: 0.9928\n",
      "Epoch 4/8\n",
      " - 15s - loss: 0.0953 - acc: 0.9858 - val_loss: 0.0358 - val_acc: 0.9922\n",
      "Epoch 5/8\n",
      " - 14s - loss: 0.0214 - acc: 0.9931 - val_loss: 0.0381 - val_acc: 0.9919\n",
      "Epoch 6/8\n",
      " - 14s - loss: 0.0175 - acc: 0.9943 - val_loss: 0.0328 - val_acc: 0.9918\n",
      "Epoch 7/8\n",
      " - 14s - loss: 0.0164 - acc: 0.9946 - val_loss: 0.0321 - val_acc: 0.9927\n",
      "Epoch 8/8\n",
      " - 15s - loss: 0.0127 - acc: 0.9956 - val_loss: 0.0322 - val_acc: 0.9933\n",
      "[stdout:6] \n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/8\n",
      " - 15s - loss: 0.2195 - acc: 0.9353 - val_loss: 0.0348 - val_acc: 0.9886\n",
      "Epoch 2/8\n",
      " - 14s - loss: 0.0406 - acc: 0.9872 - val_loss: 0.0327 - val_acc: 0.9900\n",
      "Epoch 3/8\n",
      " - 14s - loss: 0.0269 - acc: 0.9912 - val_loss: 0.0287 - val_acc: 0.9928\n",
      "Epoch 4/8\n",
      " - 15s - loss: 0.0929 - acc: 0.9857 - val_loss: 0.0358 - val_acc: 0.9922\n",
      "Epoch 5/8\n",
      " - 14s - loss: 0.0187 - acc: 0.9937 - val_loss: 0.0381 - val_acc: 0.9919\n",
      "Epoch 6/8\n",
      " - 14s - loss: 0.0180 - acc: 0.9941 - val_loss: 0.0328 - val_acc: 0.9918\n",
      "Epoch 7/8\n",
      " - 14s - loss: 0.0141 - acc: 0.9953 - val_loss: 0.0321 - val_acc: 0.9927\n",
      "Epoch 8/8\n",
      " - 15s - loss: 0.0139 - acc: 0.9957 - val_loss: 0.0322 - val_acc: 0.9933\n",
      "[stdout:7] \n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/8\n",
      " - 15s - loss: 0.2202 - acc: 0.9352 - val_loss: 0.0348 - val_acc: 0.9886\n",
      "Epoch 2/8\n",
      " - 14s - loss: 0.0416 - acc: 0.9865 - val_loss: 0.0327 - val_acc: 0.9900\n",
      "Epoch 3/8\n",
      " - 14s - loss: 0.0275 - acc: 0.9907 - val_loss: 0.0287 - val_acc: 0.9928\n",
      "Epoch 4/8\n",
      " - 15s - loss: 0.0918 - acc: 0.9853 - val_loss: 0.0358 - val_acc: 0.9922\n",
      "Epoch 5/8\n",
      " - 14s - loss: 0.0201 - acc: 0.9933 - val_loss: 0.0381 - val_acc: 0.9919\n",
      "Epoch 6/8\n",
      " - 14s - loss: 0.0174 - acc: 0.9942 - val_loss: 0.0328 - val_acc: 0.9918\n",
      "Epoch 7/8\n",
      " - 14s - loss: 0.0160 - acc: 0.9945 - val_loss: 0.0321 - val_acc: 0.9927\n",
      "Epoch 8/8\n",
      " - 15s - loss: 0.0128 - acc: 0.9956 - val_loss: 0.0322 - val_acc: 0.9933\n",
      "[stdout:8] \n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/8\n",
      " - 15s - loss: 0.2221 - acc: 0.9345 - val_loss: 0.0348 - val_acc: 0.9886\n",
      "Epoch 2/8\n",
      " - 14s - loss: 0.0374 - acc: 0.9877 - val_loss: 0.0327 - val_acc: 0.9900\n",
      "Epoch 3/8\n",
      " - 14s - loss: 0.0263 - acc: 0.9908 - val_loss: 0.0287 - val_acc: 0.9928\n",
      "Epoch 4/8\n",
      " - 15s - loss: 0.0866 - acc: 0.9865 - val_loss: 0.0358 - val_acc: 0.9922\n",
      "Epoch 5/8\n",
      " - 14s - loss: 0.0211 - acc: 0.9929 - val_loss: 0.0381 - val_acc: 0.9919\n",
      "Epoch 6/8\n",
      " - 14s - loss: 0.0171 - acc: 0.9942 - val_loss: 0.0328 - val_acc: 0.9918\n",
      "Epoch 7/8\n",
      " - 14s - loss: 0.0128 - acc: 0.9956 - val_loss: 0.0321 - val_acc: 0.9927\n",
      "Epoch 8/8\n",
      " - 15s - loss: 0.0135 - acc: 0.9956 - val_loss: 0.0322 - val_acc: 0.9933\n",
      "[stdout:9] \n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/8\n",
      " - 15s - loss: 0.2189 - acc: 0.9348 - val_loss: 0.0348 - val_acc: 0.9886\n",
      "Epoch 2/8\n",
      " - 14s - loss: 0.0396 - acc: 0.9876 - val_loss: 0.0327 - val_acc: 0.9900\n",
      "Epoch 3/8\n",
      " - 14s - loss: 0.0264 - acc: 0.9912 - val_loss: 0.0287 - val_acc: 0.9928\n",
      "Epoch 4/8\n",
      " - 15s - loss: 0.0914 - acc: 0.9860 - val_loss: 0.0358 - val_acc: 0.9922\n",
      "Epoch 5/8\n",
      " - 14s - loss: 0.0207 - acc: 0.9933 - val_loss: 0.0381 - val_acc: 0.9919\n",
      "Epoch 6/8\n",
      " - 14s - loss: 0.0151 - acc: 0.9946 - val_loss: 0.0328 - val_acc: 0.9918\n",
      "Epoch 7/8\n",
      " - 14s - loss: 0.0153 - acc: 0.9948 - val_loss: 0.0321 - val_acc: 0.9927\n",
      "Epoch 8/8\n",
      " - 15s - loss: 0.0148 - acc: 0.9954 - val_loss: 0.0322 - val_acc: 0.9933\n",
      "[stdout:10] \n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/8\n",
      " - 15s - loss: 0.2212 - acc: 0.9354 - val_loss: 0.0348 - val_acc: 0.9886\n",
      "Epoch 2/8\n",
      " - 14s - loss: 0.0412 - acc: 0.9871 - val_loss: 0.0327 - val_acc: 0.9900\n",
      "Epoch 3/8\n",
      " - 14s - loss: 0.0258 - acc: 0.9909 - val_loss: 0.0287 - val_acc: 0.9928\n",
      "Epoch 4/8\n",
      " - 15s - loss: 0.0895 - acc: 0.9861 - val_loss: 0.0358 - val_acc: 0.9922\n",
      "Epoch 5/8\n",
      " - 14s - loss: 0.0187 - acc: 0.9937 - val_loss: 0.0381 - val_acc: 0.9919\n",
      "Epoch 6/8\n",
      " - 14s - loss: 0.0166 - acc: 0.9948 - val_loss: 0.0328 - val_acc: 0.9918\n",
      "Epoch 7/8\n",
      " - 14s - loss: 0.0164 - acc: 0.9947 - val_loss: 0.0321 - val_acc: 0.9927\n",
      "Epoch 8/8\n",
      " - 15s - loss: 0.0146 - acc: 0.9952 - val_loss: 0.0322 - val_acc: 0.9933\n",
      "[stdout:11] \n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/8\n",
      " - 15s - loss: 0.2244 - acc: 0.9334 - val_loss: 0.0348 - val_acc: 0.9886\n",
      "Epoch 2/8\n",
      " - 14s - loss: 0.0389 - acc: 0.9870 - val_loss: 0.0327 - val_acc: 0.9900\n",
      "Epoch 3/8\n",
      " - 14s - loss: 0.0286 - acc: 0.9906 - val_loss: 0.0287 - val_acc: 0.9928\n",
      "Epoch 4/8\n",
      " - 15s - loss: 0.0933 - acc: 0.9853 - val_loss: 0.0358 - val_acc: 0.9922\n",
      "Epoch 5/8\n",
      " - 14s - loss: 0.0201 - acc: 0.9929 - val_loss: 0.0381 - val_acc: 0.9919\n",
      "Epoch 6/8\n",
      " - 14s - loss: 0.0168 - acc: 0.9943 - val_loss: 0.0328 - val_acc: 0.9918\n",
      "Epoch 7/8\n",
      " - 14s - loss: 0.0131 - acc: 0.9954 - val_loss: 0.0321 - val_acc: 0.9927\n",
      "Epoch 8/8\n",
      " - 15s - loss: 0.0137 - acc: 0.9953 - val_loss: 0.0322 - val_acc: 0.9933\n",
      "[stdout:12] \n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/8\n",
      " - 15s - loss: 0.2217 - acc: 0.9344 - val_loss: 0.0348 - val_acc: 0.9886\n",
      "Epoch 2/8\n",
      " - 14s - loss: 0.0394 - acc: 0.9869 - val_loss: 0.0327 - val_acc: 0.9900\n",
      "Epoch 3/8\n",
      " - 14s - loss: 0.0281 - acc: 0.9907 - val_loss: 0.0287 - val_acc: 0.9928\n",
      "Epoch 4/8\n",
      " - 15s - loss: 0.0961 - acc: 0.9850 - val_loss: 0.0358 - val_acc: 0.9922\n",
      "Epoch 5/8\n",
      " - 14s - loss: 0.0204 - acc: 0.9936 - val_loss: 0.0381 - val_acc: 0.9919\n",
      "Epoch 6/8\n",
      " - 14s - loss: 0.0167 - acc: 0.9944 - val_loss: 0.0328 - val_acc: 0.9918\n",
      "Epoch 7/8\n",
      " - 14s - loss: 0.0152 - acc: 0.9948 - val_loss: 0.0321 - val_acc: 0.9927\n",
      "Epoch 8/8\n",
      " - 15s - loss: 0.0130 - acc: 0.9957 - val_loss: 0.0322 - val_acc: 0.9933\n",
      "[stdout:13] \n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/8\n",
      " - 15s - loss: 0.2203 - acc: 0.9347 - val_loss: 0.0348 - val_acc: 0.9886\n",
      "Epoch 2/8\n",
      " - 14s - loss: 0.0404 - acc: 0.9874 - val_loss: 0.0327 - val_acc: 0.9900\n",
      "Epoch 3/8\n",
      " - 14s - loss: 0.0275 - acc: 0.9909 - val_loss: 0.0287 - val_acc: 0.9928\n",
      "Epoch 4/8\n",
      " - 15s - loss: 0.0943 - acc: 0.9848 - val_loss: 0.0358 - val_acc: 0.9922\n",
      "Epoch 5/8\n",
      " - 14s - loss: 0.0219 - acc: 0.9933 - val_loss: 0.0381 - val_acc: 0.9919\n",
      "Epoch 6/8\n",
      " - 14s - loss: 0.0166 - acc: 0.9943 - val_loss: 0.0328 - val_acc: 0.9918\n",
      "Epoch 7/8\n",
      " - 14s - loss: 0.0127 - acc: 0.9958 - val_loss: 0.0321 - val_acc: 0.9927\n",
      "Epoch 8/8\n",
      " - 15s - loss: 0.0128 - acc: 0.9955 - val_loss: 0.0322 - val_acc: 0.9933\n",
      "[stdout:14] \n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/8\n",
      " - 15s - loss: 0.2190 - acc: 0.9350 - val_loss: 0.0348 - val_acc: 0.9886\n",
      "Epoch 2/8\n",
      " - 14s - loss: 0.0390 - acc: 0.9877 - val_loss: 0.0327 - val_acc: 0.9900\n",
      "Epoch 3/8\n",
      " - 14s - loss: 0.0271 - acc: 0.9911 - val_loss: 0.0287 - val_acc: 0.9928\n",
      "Epoch 4/8\n",
      " - 15s - loss: 0.0893 - acc: 0.9857 - val_loss: 0.0358 - val_acc: 0.9922\n",
      "Epoch 5/8\n",
      " - 14s - loss: 0.0196 - acc: 0.9934 - val_loss: 0.0381 - val_acc: 0.9919\n",
      "Epoch 6/8\n",
      " - 14s - loss: 0.0168 - acc: 0.9943 - val_loss: 0.0328 - val_acc: 0.9918\n",
      "Epoch 7/8\n",
      " - 14s - loss: 0.0142 - acc: 0.9952 - val_loss: 0.0321 - val_acc: 0.9927\n",
      "Epoch 8/8\n",
      " - 15s - loss: 0.0149 - acc: 0.9950 - val_loss: 0.0322 - val_acc: 0.9933\n",
      "[stdout:15] \n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/8\n",
      " - 15s - loss: 0.2233 - acc: 0.9350 - val_loss: 0.0348 - val_acc: 0.9886\n",
      "Epoch 2/8\n",
      " - 14s - loss: 0.0400 - acc: 0.9872 - val_loss: 0.0327 - val_acc: 0.9900\n",
      "Epoch 3/8\n",
      " - 14s - loss: 0.0281 - acc: 0.9910 - val_loss: 0.0287 - val_acc: 0.9928\n",
      "Epoch 4/8\n",
      " - 15s - loss: 0.0862 - acc: 0.9862 - val_loss: 0.0358 - val_acc: 0.9922\n",
      "Epoch 5/8\n",
      " - 14s - loss: 0.0195 - acc: 0.9937 - val_loss: 0.0381 - val_acc: 0.9919\n",
      "Epoch 6/8\n",
      " - 14s - loss: 0.0161 - acc: 0.9949 - val_loss: 0.0328 - val_acc: 0.9918\n",
      "Epoch 7/8\n",
      " - 14s - loss: 0.0150 - acc: 0.9948 - val_loss: 0.0321 - val_acc: 0.9927\n",
      "Epoch 8/8\n",
      " - 15s - loss: 0.0150 - acc: 0.9950 - val_loss: 0.0322 - val_acc: 0.9933\n"
     ]
    }
   ],
   "source": [
    "%%px\n",
    "\n",
    "callbacks = [\n",
    "    # Horovod: broadcast initial variable states from rank 0 to all other processes.\n",
    "    # This is necessary to ensure consistent initialization of all workers when\n",
    "    # training is started with random weights or restored from a checkpoint.\n",
    "    hvd.callbacks.BroadcastGlobalVariablesCallback(0),\n",
    "]\n",
    "\n",
    "# Horovod: save checkpoints only on worker 0 to prevent other workers from corrupting them.\n",
    "#if hvd.rank() == 0:\n",
    "#    callbacks.append(keras.callbacks.ModelCheckpoint('./checkpoint-{epoch}.h5'))\n",
    "\n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    callbacks=callbacks,\n",
    "                    epochs=n_epochs,\n",
    "                    verbose=2,\n",
    "                    validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[stdout:0] \n",
      "Test loss: 0.03215054078726182\n",
      "Test accuracy: 0.9933\n",
      "[stdout:1] \n",
      "Test loss: 0.03215054078726182\n",
      "Test accuracy: 0.9933\n",
      "[stdout:2] \n",
      "Test loss: 0.03215054078726182\n",
      "Test accuracy: 0.9933\n",
      "[stdout:3] \n",
      "Test loss: 0.03215054078726182\n",
      "Test accuracy: 0.9933\n",
      "[stdout:4] \n",
      "Test loss: 0.03215054078726182\n",
      "Test accuracy: 0.9933\n",
      "[stdout:5] \n",
      "Test loss: 0.03215054078726182\n",
      "Test accuracy: 0.9933\n",
      "[stdout:6] \n",
      "Test loss: 0.03215054078726182\n",
      "Test accuracy: 0.9933\n",
      "[stdout:7] \n",
      "Test loss: 0.03215054078726182\n",
      "Test accuracy: 0.9933\n",
      "[stdout:8] \n",
      "Test loss: 0.03215054078726182\n",
      "Test accuracy: 0.9933\n",
      "[stdout:9] \n",
      "Test loss: 0.03215054078726182\n",
      "Test accuracy: 0.9933\n",
      "[stdout:10] \n",
      "Test loss: 0.03215054078726182\n",
      "Test accuracy: 0.9933\n",
      "[stdout:11] \n",
      "Test loss: 0.03215054078726182\n",
      "Test accuracy: 0.9933\n",
      "[stdout:12] \n",
      "Test loss: 0.03215054078726182\n",
      "Test accuracy: 0.9933\n",
      "[stdout:13] \n",
      "Test loss: 0.03215054078726182\n",
      "Test accuracy: 0.9933\n",
      "[stdout:14] \n",
      "Test loss: 0.03215054078726182\n",
      "Test accuracy: 0.9933\n",
      "[stdout:15] \n",
      "Test loss: 0.03215054078726182\n",
      "Test accuracy: 0.9933\n"
     ]
    }
   ],
   "source": [
    "%%px\n",
    "\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tensorflow 1.9 py36",
   "language": "python",
   "name": "tensorflow_1.9.0_py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
